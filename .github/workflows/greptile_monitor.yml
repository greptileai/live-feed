name: Greptile Comment Monitor

on:
  schedule:
    # Run every 2 hours
    - cron: '0 */2 * * *'
  workflow_dispatch:
    inputs:
      max_repos:
        description: 'Maximum repos to process (for testing)'
        required: false
        type: number
      limit:
        description: 'Maximum addressed comments to evaluate'
        required: false
        default: '100'
        type: string
      min_score:
        description: 'Minimum quality score (1-10)'
        required: false
        default: '8'
        type: string
      skip_evaluation:
        description: 'Skip LLM evaluation step'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.11'

jobs:
  monitor:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Evaluate addressed comments (two-phase approach)
        if: ${{ !inputs.skip_evaluation }}
        env:
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GREPTILE_DB_URL: ${{ secrets.GREPTILE_DB_URL }}
          GOOGLE_CREDENTIALS_FILE: ${{ github.workspace }}/credentials.json
        run: |
          # Write Google credentials from secret
          echo '${{ secrets.GOOGLE_CREDENTIALS_JSON }}' > credentials.json

          # Run two-phase evaluation:
          # Phase 1: Query DB for new addressed comments
          # Phase 2: Enrich with GitHub context and evaluate
          python run_addressed_evaluation.py \
            --limit ${{ inputs.limit || '100' }} \
            --min-score ${{ inputs.min_score || '8' }} \
            --output output/quality_catches.csv \
            --state-file state/evaluated_comments.json \
            --sync-sheets \
            --verbose

          # Clean up credentials
          rm -f credentials.json

      - name: Upload output as artifact
        uses: actions/upload-artifact@v4
        with:
          name: greptile-catches-${{ github.run_number }}
          path: |
            output/quality_catches.csv
            state/evaluated_comments.json
          retention-days: 30

      - name: Commit state back to repo
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add state/evaluated_comments.json || true
          git add output/quality_catches.csv || true
          git diff --staged --quiet || git commit -m "chore: update greptile monitor state [skip ci]"
          git pull --rebase origin main || true
          git push

      - name: Summary
        run: |
          echo "## Greptile Addressed Comments Evaluation" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f state/evaluated_comments.json ]; then
            echo "### Evaluation State" >> $GITHUB_STEP_SUMMARY
            TOTAL=$(jq '.evaluated_ids | length' state/evaluated_comments.json)
            LAST_CHECK=$(jq -r '.last_check // "never"' state/evaluated_comments.json)
            echo "- **Total evaluated (all time)**: $TOTAL comments" >> $GITHUB_STEP_SUMMARY
            echo "- **Last check**: $LAST_CHECK" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f output/quality_catches.csv ]; then
            echo "### Quality Catches" >> $GITHUB_STEP_SUMMARY
            TOTAL_CATCHES=$(python3 -c "import csv; print(sum(1 for _ in csv.reader(open('output/quality_catches.csv'))) - 1)")
            echo "- **Total showcase-worthy catches**: $TOTAL_CATCHES" >> $GITHUB_STEP_SUMMARY
          fi
